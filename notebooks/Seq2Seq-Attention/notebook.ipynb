{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German -> English\n",
    "\n",
    "https://www.youtube.com/watch?v=sQUqQddQtB4&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load('de')\n",
    "spacy_eng = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenizer_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenizer_ger, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "english = Field(tokenize=tokenizer_eng, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(german, english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        if num_layers == 1:\n",
    "            # dropout will not work if you only have one layer\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers,\n",
    "                               bidirectional=True, dropout=p)\n",
    "\n",
    "        # instead of limiting the information to just forward or backward\n",
    "        # we send it through a linear layer\n",
    "        # NOTE: we make use of the information (from LSTM, forward and backward) by\n",
    "        #       using linear layer to map it from (hidden_size * 2) to just hidden_size\n",
    "        #       since Decoder will not be bidirectional.\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        # encoder_states has forward and backward hidden states\n",
    "        # hidden only has the right most states\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # encoder_states shape: (seq_length, N, hidden_size)\n",
    "        \n",
    "        # NOTE: encoder_states which remembers are really just the hidden values\n",
    "        #       for every timestep (since we don't run through encoder_states from\n",
    "        #       encoder through any additional linear layers), hence it will be hidden_size * 2 in size for\n",
    "        #       final dimension.\n",
    "\n",
    "        # [0:1] is the hidden state for forward\n",
    "        # [1:2] is the hidden state for backward\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        # hidden, cell shape: (2, N, hidden_size)\n",
    "\n",
    "        return encoder_states, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        # hidden_size * 2 because we have encoder_state (forward and backward)\n",
    "        # hidden_size * 2 is context vector from the encoder\n",
    "        # embedding_size is the normal\n",
    "        if num_layers == 1:\n",
    "            # dropout will not work if you only have one layer\n",
    "            self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers, dropout=p)\n",
    "\n",
    "        # add hidden_states (forward + backward) from encoder; hidden_states from previous step in decoder\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.softmax = nn.Softmax(dim=0)  # activation function for the attention layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        \"\"\"\n",
    "        encoder_states: hidden_states from the encoder\n",
    "        hidden: hidden_states from the decoder\n",
    "        \"\"\"\n",
    "\n",
    "        # x shape: (N) but we want (1, N)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        # compute energy states\n",
    "        # hidden_states from encoder (forward + backward) and hidden_states from decoder\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        # repeat hidden_states (from decoder) along each time steps from encoder\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "\n",
    "        # concat previous hidden_states from decoder with the encoder_states (hidden states from the encoder)\n",
    "        # and send through one layer neural network to compute the \"energy states\"\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "\n",
    "        # compute attention scores from softmax activation function\n",
    "        # the reason of computing the attention score to learn which hidden states (from decoder)\n",
    "        # we should pay attention to\n",
    "        attention = self.softmax(energy)\n",
    "        # attention shape: (sequence_length, N, 1)\n",
    "\n",
    "        # multiply attention with encoder_states\n",
    "        attention = attention.permute(1, 2, 0)  # swap orders\n",
    "        # attention shape: (N, 1, seq_length)\n",
    "\n",
    "        encoder_states = encoder_states.permute(1, 0, 2)\n",
    "        # encoder_states shape: (N, seq_length, hidden_size * 2)\n",
    "\n",
    "        # multiply the attention scores with encoder hidden_states\n",
    "        context_vector = torch.bmm(attention, encoder_states).permute(1, 0, 2)\n",
    "        # context_vector shape: (N, 1, hidden_size * 2) -> (1, N, hidden_size * 2)\n",
    "\n",
    "        # concat the context_vector with the embedding on hidden_size (dimension 2)\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # output shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "        # predictions shape: (1, N, length_of_vocab)\n",
    "\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input of the decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            outputs[t] = output\n",
    "            # output shape: (N, english_vocab_size)\n",
    "\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "\n",
    "# embeeding_size of around 100-300 is good number\n",
    "# based on size of the dataset\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "\n",
    "hidden_size = 1024\n",
    "num_layers = 1  # number of layers, 1 did the best during the experimentation\n",
    "enc_dropout = 0.5  # if num_layers is 1, there can be no dropout\n",
    "dec_dropout = 0.5  # if num_layers is 1, there can be no dropout\n",
    "\n",
    "\n",
    "# Tensorboard\n",
    "writer = SummaryWriter(f'runs/loss_plot')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = batch_size,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device\n",
    ")\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder,\n",
    "    encoder_embedding_size,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoc [0 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['archway', 'unfriendly', 'viewing', 'year', 'steering', 'sashes', 'ultimate', 'retail', 'fatigued', 'appreciate', 'youth', 'racquet', 'gripping', 'marching', 'pitched', 'spotlights', 'bowls', 'rally', 'equipped', 'no', 'affection', 'affection', 'scores', 'woven', 'camel', 'treats', 'vaulting', 'sideline', 'stilts', 'safe', 'soil', 'presses', 'sleeve', 'fun', 'stretching', 'rope', 'spray', 'interior', 'uniformed', 'buddhist', 'eagerly', 'senior', 'consisting', 'observes', 'after', 'shuffles', 'burger', 'bookshelf', 'bookshelf', 'ninja']\n",
      "\n",
      "Epoc [1 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'couple', 'with', 'a', 'large', '<unk>', '<unk>', '<unk>', 'on', 'a', 'large', '<unk>', '.', '<eos>']\n",
      "\n",
      "Epoc [2 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'large', 'with', 'with', 'men', 'on', 'a', 'large', '<unk>', 'by', 'a', 'large', 'of', 'a', 'large', '.', '.', '<eos>']\n",
      "\n",
      "Epoc [3 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'with', 'with', 'large', 'number', '<unk>', 'is', 'being', 'pulled', 'by', 'a', 'large', 'of', 'a', '.', '<eos>']\n",
      "\n",
      "Epoc [4 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'with', 'five', 'men', 'being', 'pulled', 'by', 'a', 'large', 'by', 'a', '.', '<eos>']\n",
      "\n",
      "Epoc [5 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'with', 'several', 'men', 'is', 'being', 'pulled', 'by', 'a', 'large', 'of', 'a', 'large', 'cable', '.', '<eos>']\n",
      "\n",
      "Epoc [6 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'with', 'several', 'men', 'is', '<unk>', 'by', 'by', 'a', 'large', 'cable', 'by', 'a', '.', '<eos>']\n",
      "\n",
      "Epoc [7 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'boat', 'is', 'being', 'pulled', 'by', 'by', 'by', 'a', 'large', 'team', 'of', 'horses', 'men', '.', '<eos>']\n",
      "\n",
      "Epoc [8 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'boat', 'men', 'men', 'is', 'pulled', 'away', 'from', 'a', 'a', 'a', 'a', 'a', 'team', '.', '<eos>']\n",
      "\n",
      "Epoc [9 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'of', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [10 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'two', 'men', 'being', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [11 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [12 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [13 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [14 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [15 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [16 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'is', 'being', 'pulled', '.', '<eos>']\n",
      "\n",
      "Epoc [17 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [18 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n",
      "\n",
      "Epoc [19 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence \n",
      " ['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load('my_checkpoint.pth.tar'), model, optimizer)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoc [{epoch} / {num_epochs}]')\n",
    "\n",
    "    checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(model, sentence, german, english, device, max_length=50)\n",
    "\n",
    "    print(f'Translated example sentence \\n {translated_sentence}')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        input_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        output = model(input_data, target)\n",
    "        # output shape: (trg_len, batch_size, output_dim)\n",
    "\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # to avoid gradient becomes too large\n",
    "        # make sure that gradients are in healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('Training loss', loss, global_step=step)\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score 24.71\n"
     ]
    }
   ],
   "source": [
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
